http://discuss.itversity.com/search?q=hive%20pyspark%20metastore
http://discuss.itversity.com/t/not-able-to-access-default-database-in-pyspark/7157

    Removed the linked file using sudo rm -R /etc/spar/conf/hive.xml
    Again linked the file using sudo ln -s /etc/hive/conf/hive-site.xml /etc/spark/conf/hive-site.xml

sudo ln -s /usr/lib/hive/conf/hive-site.xml /usr/lib/spark/conf/hive-site.xml



from pyspark.sql import HiveContext
hiveContext = HiveContext(sc)

products_over_100 = hiveContext.sql("""
	 select *
	 from default.product_replica
	 where product_price > 100
""")

products_over_100 = sqlContext.sql("""
	 select *
	 from default.product_replica
	 where product_price > 100
""")

sqlContext.sql("CREATE TABLE IF NOT EXISTS mytable AS SELECT * FROM customers")


val hiveContext=new org.apache.spark.sql.hive.HiveContext(sc)
val products_over_100 = hiveContext.sql("""
	 select *
	 from default.product_replica
	 where product_price > 100
""")